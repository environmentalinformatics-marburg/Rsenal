% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/statFDR.R
\name{statFDR}
\alias{statFDR}
\title{Calculate FDR for a given number of test runs}
\usage{
statFDR(n, prevalence = 0.1, sensitivity = 0.8, p.val = 0.05)
}
\arguments{
\item{n}{the number of tests (e.g. the number of pixels for pixel-wise calculations)}

\item{prevalence}{the fraction of real effects present (this is a guess!!)}

\item{sensitivity}{the sensitivity of the test, i.e. how likely it is 
that the test will discover an effect if there is one}

\item{p.val}{the p-value to be acceptable}
}
\description{
this function calculates the False Discovery Rate for a statistical test
based on its sensitivity, the assumed prevalence of the effect and the
specificity of the test.
}
\examples{
## reproducing Figure 1 from \\url{http://rsos.royalsocietypublishing.org/content/1/3/140216}
n <- 10000
prev <- 0.01
sens <- 0.8
p_val <- 0.05

statFDR(n, prev, sens, p_val)


}
\references{
Review article:
An investigation of the false discovery rate and the misinterpretation of p-values

David Colquhoun
R. Soc. open sci. 2014 1 140216; DOI: 10.1098/rsos.140216. Published 19 November 2014
}
\author{
Tim Appelhans
}
